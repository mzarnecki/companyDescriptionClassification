{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas for DataFrame processing and nltk for text normalization \n",
    "import pandas as pd \n",
    "import nltk\n",
    "\n",
    "#load csv into DataFrame \n",
    "train = pd.read_csv('data/data.csv', header=None, names=['purpose', 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purpose</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gegenstand des Unternehmens dienlich sein können.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geschäftsgegenstand ist die Produktion pflanzl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gegenstand ist die Erbringung von Dienstleistu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dienstleistungen aller Art, für die keine beso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbau von Obst und Gemüse, Vertrieb von selbst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             purpose  code\n",
       "0  Gegenstand des Unternehmens dienlich sein können.     1\n",
       "1  Geschäftsgegenstand ist die Produktion pflanzl...     1\n",
       "2  Gegenstand ist die Erbringung von Dienstleistu...     1\n",
       "3  Dienstleistungen aller Art, für die keine beso...     1\n",
       "4  Anbau von Obst und Gemüse, Vertrieb von selbst...     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check first records to see how data is shaped\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.925694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.508289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>382.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count\n",
       "count  1117.000000\n",
       "mean     22.925694\n",
       "std      21.508289\n",
       "min       1.000000\n",
       "25%      11.000000\n",
       "50%      17.000000\n",
       "75%      28.000000\n",
       "max     382.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display statistics of words count to check later progress after text normalization\n",
    "train['word_count'] = train['purpose'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train[['word_count']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "train['purpose'] = train['purpose'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase\n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rzar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download german language specifics stop words (common words that only complicate computation without bringing important information)\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('german')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove stop words\n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sowie                        589\n",
       "betrieb                      308\n",
       "handel                       279\n",
       "vertrieb                     237\n",
       "kies                         227\n",
       "gegenstand                   222\n",
       "sand                         205\n",
       "gesellschaft                 194\n",
       "art                          189\n",
       "unternehmens                 179\n",
       "landwirtschaftlichen         161\n",
       "gewinnung                    161\n",
       "insbesondere                 145\n",
       "unternehmen                  138\n",
       "produktion                   116\n",
       "geschäftsgegenstand          109\n",
       "erzeugung                    106\n",
       "landwirtschaftlicher         101\n",
       "herstellung                  101\n",
       "dienstleistungen              98\n",
       "durchführung                  97\n",
       "geschäfte                     96\n",
       "deren                         90\n",
       "verarbeitung                  90\n",
       "verkauf                       88\n",
       "aufbereitung                  87\n",
       "vermarktung                   82\n",
       "baustoffen                    76\n",
       "zusammenhang                  74\n",
       "produkte                      68\n",
       "                            ... \n",
       "kommanditistin                 2\n",
       "friedrich                      2\n",
       "nawaro                         2\n",
       "eigentums                      2\n",
       "betonherstellung               2\n",
       "zwethau                        2\n",
       "schwerin                       2\n",
       "handelsgeschäftes              2\n",
       "wasserbau                      2\n",
       "generalversammlung             2\n",
       "zb                             2\n",
       "fremder                        2\n",
       "schorfheidechorin              2\n",
       "kalksteinwerke                 2\n",
       "rechtsträgers                  2\n",
       "baggerbetrieb                  2\n",
       "acker                          2\n",
       "fördernder                     2\n",
       "geräte                         2\n",
       "rechte                         2\n",
       "bodensubstanzen                2\n",
       "embsen                         2\n",
       "betonzuschlagstoffen           2\n",
       "gesellschaftern                2\n",
       "beratungsdienstleistungen      2\n",
       "pflegestelle                   2\n",
       "karlheinz                      2\n",
       "recht                          2\n",
       "kommunalen                     2\n",
       "rechtsträger                   2\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get frequent words which dont bring important information \n",
    "freq = pd.Series(' '.join(train['purpose']).split()).value_counts()[:1000]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually choose frequent words which could be removed as they are not related to topic classification\n",
    "freqWords = ['sowie', 'insbesondere', 'unternehmen', 'gegenstand', 'tätigkeiten', 'deren', 'gmbh', 'beteiligen', 'einschließlich', 'firma', 'eigenen', 'zweigniederlassungen', 'sitz', 'berechtigt', 'sonstigen', 'ferner', 'zusammenhängenden', 'zwecke', 'zweck', 'co', 'kg', 'gesellschaftszweck', 'amtsgericht', 'organisation', 'soweit', 'b', 'a', 'geeignet', 'ähnlichen', 'tätigkeit', 'ähnlicher', 'gleicher']\n",
    "#remove popular words\n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join(x for x in x.split() if x not in freqWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove numeric - in this case numbers also dont bring much information \n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join(x for x in x.split() if not x.isnumeric()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get also list of rare words that are to specific to use in model\n",
    "freq = pd.Series(' '.join(train['purpose']).split()).value_counts()\n",
    "rareWords = freq[freq < 6]\n",
    "#remove rare words\n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join(x for x in x.split() if x not in rareWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rzar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#download german lemmatizer to simplify word vectors (normalize words to same form)\n",
    "nltk.download('punkt')\n",
    "from textblob_de.lemmatizers import PatternParserLemmatizer\n",
    "_lemmatizer = PatternParserLemmatizer()\n",
    "train['purpose'] = train['purpose'].apply(lambda x: \" \".join([_lemmatizer.lemmatize(word)[0][0] for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vestorize TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "tfidfconverter = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.7)  \n",
    "X = tfidfconverter.fit_transform(train['purpose']).toarray()\n",
    "y = train['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to train and test set\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get RandomForestClassifier which is suitable for this kind of classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 92  13]\n",
      " [  5 114]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.95      0.88      0.91       105\n",
      "          8       0.90      0.96      0.93       119\n",
      "\n",
      "avg / total       0.92      0.92      0.92       224\n",
      "\n",
      "0.9196428571428571\n"
     ]
    }
   ],
   "source": [
    "#evaluate trained model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#export model (could be used for real time service)\n",
    "with open('purposeToIndustryCodeLv1', 'wb') as picklefile:  \n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model\n",
    "with open('purposeToIndustryCodeLv1', 'rb') as training_model:  \n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 1),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 8),\n",
       " (8, 1),\n",
       " (8, 8)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare predicted classes to real ones\n",
    "y_pred2 = model.predict(X_test)\n",
    "list(zip(list(y_test), y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
